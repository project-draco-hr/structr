{
  final int maxWordsToIndex=Services.parseInt(StructrApp.getConfigurationValue(Services.APPLICATION_FILESYSTEM_INDEXING_LIMIT),100);
  boolean parsingSuccessful=false;
  InputStream inputStream=null;
  try (final Tx tx=StructrApp.getInstance().tx()){
    System.out.println("Extracting content from " + file.getName() + "...");
    inputStream=file.getInputStream();
    tx.success();
  }
 catch (  FrameworkException fex) {
    fex.printStackTrace();
  }
  if (inputStream != null) {
    final FulltextTokenizer tokenizer=new FulltextTokenizer();
    try (final InputStream is=inputStream){
      new AutoDetectParser().parse(is,new BodyContentHandler(tokenizer),new Metadata());
      parsingSuccessful=true;
    }
 catch (    Throwable t) {
      t.printStackTrace();
    }
    if (parsingSuccessful) {
      try (final Tx tx=StructrApp.getInstance().tx()){
        System.out.println("Indexing " + file.getName() + "...");
        final NodeService nodeService=Services.getInstance().getService(NodeService.class);
        final Index<Node> fulltextIndex=nodeService.getNodeIndex(NodeService.NodeIndex.fulltext);
        final String indexKeyName=FileBase.indexedContent.jsonName();
        final Node node=file.getNode();
        file.setProperty(extractedContent,tokenizer.getRawText());
        tokenizer.write(getName());
        final Principal _owner=file.getProperty(owner);
        if (_owner != null) {
          final String ownerName=_owner.getName();
          if (ownerName != null) {
            tokenizer.write(ownerName);
          }
          final String eMail=_owner.getProperty(User.eMail);
          if (eMail != null) {
            tokenizer.write(eMail);
          }
          final String twitterName=_owner.getProperty(User.twitterName);
          if (twitterName != null) {
            tokenizer.write(twitterName);
          }
        }
        fulltextIndex.remove(node,indexKeyName);
        final Set<String> stopWords=languageStopwordMap.get(tokenizer.getLanguage());
        final StringBuilder buf=new StringBuilder();
        int indexedWords=0;
        for (        final String word : tokenizer.getWords()) {
          if (!stopWords.contains(word)) {
            buf.append(word + " ");
            fulltextIndex.add(node,indexKeyName,word);
          }
          if (indexedWords++ > maxWordsToIndex) {
            break;
          }
        }
        file.setProperty(FileBase.indexedWords,buf.toString());
        tx.success();
      }
 catch (      Throwable t) {
        t.printStackTrace();
      }
    }
  }
}
